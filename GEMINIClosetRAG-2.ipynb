{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6Mxxm_U38AD7"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-genai langchain langchain-community faiss-cpu pdfminer.six pillow pandas\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.embeddings import Embeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "# ---------------------------\n",
        "# Gemini Client Setup\n",
        "# ---------------------------\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOURAPIKEY\"  #change API key\n",
        "API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "assert API_KEY, \"GOOGLE_API_KEY env var is not set\"\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "# Choose your Gemini model\n",
        "GEMINI_MODEL = \"gemini-2.5-flash\"  # or \"gemini-1.5-pro\", \"gemini-1.5-flash\"\n",
        "\n",
        "# ---------------------------\n",
        "# Config\n",
        "# ---------------------------\n",
        "DOC_PATH = \"BeginnerGuide_howtodress.pdf\"\n",
        "INDEX_DIR = \"faiss_index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bSKixZbx7qkK"
      },
      "outputs": [],
      "source": [
        "# For embeddings, we'll use a simple approach with Gemini's embedding model\n",
        "class GeminiEmbeddings(Embeddings):\n",
        "    def __init__(self, client, model=\"text-embedding-004\"):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        embeddings = []\n",
        "        for text in texts:\n",
        "            result = self.client.models.embed_content(\n",
        "                model=self.model,\n",
        "                contents=text\n",
        "            )\n",
        "            embeddings.append(result.embeddings[0].values)\n",
        "        return embeddings\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        result = self.client.models.embed_content(\n",
        "            model=self.model,\n",
        "            contents=text\n",
        "        )\n",
        "        return result.embeddings[0].values\n",
        "\n",
        "embeddings = GeminiEmbeddings(client)\n",
        "\n",
        "# ---------------------------\n",
        "# PDF -> Documents\n",
        "# ---------------------------\n",
        "def load_pdf_as_documents(path: str) -> List[Document]:\n",
        "    \"\"\"Extract text from PDF and create documents with page metadata.\"\"\"\n",
        "    raw = extract_text(path) or \"\"\n",
        "    pages = [p.strip() for p in raw.split(\"\\f\") if p.strip()]\n",
        "    docs = []\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        docs.append(Document(page_content=page, metadata={\"source\": path, \"page\": i}))\n",
        "    return docs\n",
        "\n",
        "# ---------------------------\n",
        "# Chunking\n",
        "# ---------------------------\n",
        "def chunk_docs(docs: List[Document]) -> List[Document]:\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=120,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        "    )\n",
        "    return splitter.split_documents(docs)\n",
        "\n",
        "# ---------------------------\n",
        "# Build / Load Vector Store\n",
        "# ---------------------------\n",
        "def get_vectorstore(chunks: List[Document]) -> FAISS:\n",
        "    if Path(INDEX_DIR).exists():\n",
        "        db = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)\n",
        "    else:\n",
        "        db = FAISS.from_documents(chunks, embeddings)\n",
        "        db.save_local(INDEX_DIR)\n",
        "    return db\n",
        "\n",
        "# ---------------------------\n",
        "# Retrieval\n",
        "# ---------------------------\n",
        "def retrieve_docs(db: FAISS, query: str, k: int = 5) -> List[Document]:\n",
        "    retriever = db.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\"k\": k, \"fetch_k\": 20, \"lambda_mult\": 0.5}\n",
        "    )\n",
        "    return retriever.get_relevant_documents(query)\n",
        "\n",
        "def format_context(docs: List[Document], max_chars_per_chunk: int = 900) -> str:\n",
        "    blocks = []\n",
        "    for d in docs:\n",
        "        page = d.metadata.get(\"page\", \"?\")\n",
        "        text = d.page_content.strip().replace(\"\\n\", \" \")\n",
        "        if len(text) > max_chars_per_chunk:\n",
        "            text = text[:max_chars_per_chunk] + \"…\"\n",
        "        blocks.append(f\"[p.{page}] {text}\")\n",
        "    return \"\\n\\n\".join(blocks)\n",
        "\n",
        "def format_citations(docs: List[Document]) -> str:\n",
        "    pages = []\n",
        "    for d in docs:\n",
        "        p = d.metadata.get(\"page\", None)\n",
        "        if p is not None:\n",
        "            pages.append(int(p))\n",
        "    pages = sorted(set(pages))\n",
        "    if not pages:\n",
        "        return \"Sources: (no page markers)\"\n",
        "    return \"Sources: \" + \", \".join([f\"p.{p}\" for p in pages])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptJNqpvV8Nxg",
        "outputId": "d295dba7-8531-4bfe-a996-b3657a51a5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Simple Q&A Test ===\n",
            "To dress for a funeral using your black linen pants, focus on a respectful and understated tone.\n",
            "\n",
            "Here's how to style them:\n",
            "\n",
            "**Actionable Steps:**\n",
            "1.  **Choose a Top:** Pair your black linen pants with a simple top in a dark or muted color (such as black, charcoal, navy, or deep green).\n",
            "2.  **Select Shoes:** Wear closed-toe shoes.\n",
            "3.  **Accessorize Minimally:** Keep jewelry and other accessories minimal.\n",
            "4.  **Consider Outerwear:** If needed, add a formal coat, potentially in velvet or wool.\n",
            "5.  **Ensure Fit:** Tailor small things; they make the biggest difference. Ensure your pants are neat.\n",
            "\n",
            "**Ready-to-Wear Outfit Formula:**\n",
            "Black linen pants + Simple dark top + Closed-toe shoes + Minimal accessories\n",
            "\n",
            "**General guidance:**\n",
            "The context specifies dark or muted colors for funerals, which your black linen pants fulfill. While the context doesn't explicitly mention linen as an appropriate fabric for funeral pants, it does suggest velvet/wool for formal coats. Generally, for funerals, fabrics that appear neat and non-casual are preferred. If your linen pants are well-maintained, crisp, and have a more tailored look (e.g., slim-straight or wide-leg as mentioned for neatness), they may be suitable.\n",
            "\n",
            "Sources: p.7, p.4, p.8\n",
            "\n",
            "\n",
            "=== Outfit Generation Test ===\n",
            "Top: T1 — Black crewneck knit (color: black, pattern: solid, fabric: wool)\n",
            "Bottom: B1 — Black linen pants (color: black, pattern: solid, fabric: linen)\n",
            "Outerwear: O3 — Black wool overcoat (color: black, pattern: solid, fabric: wool)\n",
            "Shoes: S1 — Black leather loafers (color: black, pattern: solid, fabric: leather)\n",
            "Bag: G2 — Slim black crossbody (color: black, pattern: solid, fabric: leather)\n",
            "Accessory: A1 — Small silver hoops (color: silver, pattern: solid, fabric: metal)\n",
            "\n",
            "Why this works:\n",
            "This outfit adheres to the funeral dress code by being respectful and understated, using dark colors (black) as specified. The black linen pants (B1) are paired with a simple black knit top (T1) and a formal black wool overcoat (O3). Closed-toe black loafers (S1) are chosen, and a slim black crossbody bag (G2) along with small silver hoops (A1) provide minimal accessories, aligning with the guidelines.\n",
            "Sources: p.7, p.8\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# Gemini Generation Functions\n",
        "# ---------------------------\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a friendly, practical fashion assistant. \"\n",
        "    \"Use ONLY the provided context to answer. If the context is missing something, \"\n",
        "    \"say what is known from the context and then clearly mark any extra as 'General guidance'. \"\n",
        "    \"Give actionable steps and at least one ready-to-wear outfit formula. \"\n",
        "    \"Keep the tone concise and reassuring.\"\n",
        ")\n",
        "\n",
        "def generate_with_gemini(prompt: str, system_prompt: str = SYSTEM_PROMPT) -> str:\n",
        "    \"\"\"Generate text using Gemini API.\"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model=GEMINI_MODEL,\n",
        "        contents=prompt,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=system_prompt,\n",
        "            temperature=0.0,\n",
        "            max_output_tokens=500,\n",
        "        )\n",
        "    )\n",
        "    return response.text.strip()\n",
        "\n",
        "# ---------------------------\n",
        "# End-to-end QA\n",
        "# ---------------------------\n",
        "def answer_question(query: str) -> str:\n",
        "    docs = load_pdf_as_documents(DOC_PATH)\n",
        "    chunks = chunk_docs(docs)\n",
        "    db = get_vectorstore(chunks)\n",
        "    top_docs = retrieve_docs(db, query, k=5)\n",
        "    context = format_context(top_docs)\n",
        "\n",
        "    prompt = (\n",
        "        f\"User question:\\n{query}\\n\\n\"\n",
        "        f\"Context (excerpts with page numbers):\\n{context}\\n\\n\"\n",
        "        \"Now write the best possible answer grounded in the context. \"\n",
        "        \"Finish with a 'Sources:' line listing the page numbers you used like p.3, p.5.\"\n",
        "    )\n",
        "\n",
        "    model_answer = generate_with_gemini(prompt)\n",
        "\n",
        "    if \"Sources:\" not in model_answer:\n",
        "        model_answer += \"\\n\\n\" + format_citations(top_docs)\n",
        "    return model_answer\n",
        "\n",
        "# ================== Closet Management ==================\n",
        "def load_closet(path: str) -> pd.DataFrame:\n",
        "    if path.lower().endswith(\".csv\"):\n",
        "        df = pd.read_csv(path)\n",
        "    elif path.lower().endswith(\".json\"):\n",
        "        df = pd.DataFrame(json.load(open(path)))\n",
        "    else:\n",
        "        raise ValueError(\"Closet must be .csv or .json\")\n",
        "\n",
        "    df.columns = [c.strip().lower() for c in df.columns]\n",
        "\n",
        "    # Required columns: object, color, pattern, fabric\n",
        "    for col in [\"object\", \"color\", \"pattern\", \"fabric\"]:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Closet missing column: {col}\")\n",
        "\n",
        "    # Create ID from index if not present\n",
        "    if \"id\" not in df.columns:\n",
        "        df[\"id\"] = df.index.astype(str)\n",
        "\n",
        "    # Compact description for prompting\n",
        "    df[\"desc\"] = df.apply(\n",
        "        lambda r: f'{r[\"id\"]}: {r[\"object\"]} (color={r[\"color\"]}, pattern={r[\"pattern\"]}, fabric={r[\"fabric\"]})',\n",
        "        axis=1\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def closet_lines(df: pd.DataFrame, max_items: int = 120) -> List[str]:\n",
        "    rows = df.head(max_items)\n",
        "    return rows[\"desc\"].tolist()\n",
        "\n",
        "# ---------------------------\n",
        "# JSON Parsing\n",
        "# ---------------------------\n",
        "def extract_json(text: str):\n",
        "    \"\"\"Extract and parse JSON from Gemini response.\"\"\"\n",
        "    # Remove code fences\n",
        "    text = re.sub(r\"^```[\\w-]*\\s*|```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
        "\n",
        "    # Normalize smart quotes\n",
        "    text = (text\n",
        "        .replace(\"\\u201c\", '\"').replace(\"\\u201d\", '\"')\n",
        "        .replace(\"\\u2018\", \"'\").replace(\"\\u2019\", \"'\"))\n",
        "\n",
        "    # Strip comments\n",
        "    text = re.sub(r\"/\\*.*?\\*/\", \"\", text, flags=re.DOTALL)\n",
        "    text = re.sub(r\"(?m)^\\s*//.*$\", \"\", text)\n",
        "    text = re.sub(r\"(?m)(?<!https:)(?<!http:)//.*$\", \"\", text)\n",
        "\n",
        "    # Find JSON block\n",
        "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
        "    if not m:\n",
        "        raise ValueError(\"No JSON object found in model output.\")\n",
        "    snippet = m.group(0)\n",
        "\n",
        "    # Replace Python literals\n",
        "    snippet = re.sub(r\"\\bNone\\b\", \"null\", snippet)\n",
        "    snippet = re.sub(r\"\\bTrue\\b\", \"true\", snippet)\n",
        "    snippet = re.sub(r\"\\bFalse\\b\", \"false\", snippet)\n",
        "\n",
        "    # Remove trailing commas\n",
        "    for _ in range(3):\n",
        "        snippet = re.sub(r\",\\s*([\\]}])\", r\"\\1\", snippet)\n",
        "\n",
        "    try:\n",
        "        return json.loads(snippet)\n",
        "    except json.JSONDecodeError:\n",
        "        # Try to fix single quotes\n",
        "        def safe_double_quotes(s):\n",
        "            s = re.sub(r\"(?<=\\{|,)\\s*'([^']+)'\\s*:\", r'\"\\1\":', s)\n",
        "            s = re.sub(r':\\s*\\'([^\\'\\\\]*(?:\\\\.[^\\'\\\\]*)*)\\'', r': \"\\1\"', s)\n",
        "            return s\n",
        "        coerced = safe_double_quotes(snippet)\n",
        "        return json.loads(coerced)\n",
        "\n",
        "# ---------------------------\n",
        "# Validation\n",
        "# ---------------------------\n",
        "def validate_selection(sel: Dict[str, Any], closet_df: pd.DataFrame) -> Dict[str, Any]:\n",
        "    valid_ids = set(closet_df[\"id\"].astype(str))\n",
        "    for slot in [\"dress\",\"top\",\"bottom\",\"outerwear\",\"shoes\",\"bag\"]:\n",
        "        v = sel.get(slot)\n",
        "        if v is not None and not (isinstance(v, str) and v in valid_ids):\n",
        "            sel[slot] = None\n",
        "\n",
        "    acc = sel.get(\"accessories\", [])\n",
        "    if isinstance(acc, list):\n",
        "        sel[\"accessories\"] = [a for a in acc if isinstance(a, str) and a in valid_ids]\n",
        "    else:\n",
        "        sel[\"accessories\"] = []\n",
        "\n",
        "    essentials_ok = bool(sel.get(\"shoes\")) and (\n",
        "        bool(sel.get(\"dress\")) or (bool(sel.get(\"top\")) and bool(sel.get(\"bottom\")))\n",
        "    )\n",
        "    sel[\"_status\"] = \"ok\" if essentials_ok else \"insufficient\"\n",
        "    return sel\n",
        "\n",
        "# ---------------------------\n",
        "# Outfit Generation with Gemini\n",
        "# ---------------------------\n",
        "SCHEMA_STR = r\"\"\"\n",
        "Return ONLY JSON (no code fences, no prose) matching exactly:\n",
        "{\n",
        "  \"deduced_event\": \"short string\",\n",
        "  \"constraints\": [\"short bullets inferred from context\"],\n",
        "  \"selected\": {\n",
        "    \"dress\": \"ID or null\",\n",
        "    \"top\": \"ID or null\",\n",
        "    \"bottom\": \"ID or null\",\n",
        "    \"outerwear\": \"ID or null\",\n",
        "    \"shoes\": \"ID or null\",\n",
        "    \"bag\": \"ID or null\",\n",
        "    \"accessories\": [\"IDs\"]\n",
        "  },\n",
        "  \"explanation\": \"Under 6 sentences explaining why this works, grounded in context.\",\n",
        "  \"citations\": [\"p.7\",\"p.8\"]\n",
        "}\n",
        "Do not include any comments or Markdown.\n",
        "\"\"\"\n",
        "\n",
        "OUTFIT_SYSTEM_PROMPT = (\n",
        "    \"You are a fashion assistant. Infer appropriate styling rules from the provided context excerpts \"\n",
        "    \"(with page numbers) and assemble an outfit using ONLY closet item IDs. Do NOT invent items. \"\n",
        "    \"If you cannot complete a full outfit, still return valid JSON with nulls where needed. \"\n",
        "    \"Absolutely no text outside the JSON object. No comments. No code fences.\"\n",
        ")\n",
        "\n",
        "def llm_outfit_from_closet(user_query: str, closet_df: pd.DataFrame,\n",
        "                           doc_path: str, k: int = 6, max_closet_items: int = 120) -> Dict[str, Any]:\n",
        "    # Retrieve guide context via RAG\n",
        "    docs = load_pdf_as_documents(doc_path)\n",
        "    chunks = chunk_docs(docs)\n",
        "    db = get_vectorstore(chunks)\n",
        "    top_docs = retrieve_docs(db, user_query, k=k)\n",
        "\n",
        "    context = format_context(top_docs, max_chars_per_chunk=700)\n",
        "    citations = format_citations(top_docs)\n",
        "    closet_inv = \"\\n\".join(closet_lines(closet_df, max_closet_items))\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"User query:\\n{user_query}\\n\\n\"\n",
        "        f\"Context (excerpts with page numbers):\\n{context}\\n\\n\"\n",
        "        f\"Citations for reference: {citations}\\n\\n\"\n",
        "        \"Closet inventory (use ONLY these item IDs):\\n\"\n",
        "        f\"{closet_inv}\\n\\n\"\n",
        "        \"Instructions:\\n\"\n",
        "        \"- Infer the event/style constraints ONLY from the context above.\\n\"\n",
        "        \"- Build an outfit using only closet item IDs. If needed, a dress can stand alone (no top/bottom).\\n\"\n",
        "        \"- Keep total colors cohesive (2–3) only if context suggests; otherwise prioritize context guidance.\\n\"\n",
        "        \"- Do not repeat the full closet; do not add commentary outside JSON.\\n\"\n",
        "        + SCHEMA_STR\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=GEMINI_MODEL,\n",
        "        contents=user_prompt,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=OUTFIT_SYSTEM_PROMPT,\n",
        "            temperature=0.2,\n",
        "            max_output_tokens=400,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    raw_out = response.text.strip()\n",
        "    data = extract_json(raw_out)\n",
        "\n",
        "    # Safety: ensure keys exist\n",
        "    data.setdefault(\"selected\", {})\n",
        "    for k_ in [\"dress\",\"top\",\"bottom\",\"outerwear\",\"shoes\",\"bag\",\"accessories\"]:\n",
        "        data[\"selected\"].setdefault(k_, None if k_ != \"accessories\" else [])\n",
        "\n",
        "    # Validate IDs\n",
        "    data[\"selected\"] = validate_selection(data[\"selected\"], closet_df)\n",
        "\n",
        "    # Ensure citations present\n",
        "    if not data.get(\"citations\"):\n",
        "        data[\"citations\"] = re.findall(r\"p\\.\\d+\", citations) or []\n",
        "\n",
        "    return data\n",
        "\n",
        "# ---------------------------\n",
        "# Pretty Printer\n",
        "# ---------------------------\n",
        "def render_outfit(data: Dict[str, Any], closet_df: pd.DataFrame) -> str:\n",
        "    lines = []\n",
        "    sel = data[\"selected\"]\n",
        "\n",
        "    def lookup(i):\n",
        "        if not i: return \"\"\n",
        "        row = closet_df[closet_df[\"id\"].astype(str)==str(i)]\n",
        "        if row.empty: return i\n",
        "        r = row.iloc[0]\n",
        "        return f'{i} — {r[\"object\"]} (color: {r[\"color\"]}, pattern: {r[\"pattern\"]}, fabric: {r[\"fabric\"]})'\n",
        "\n",
        "    for slot in [\"dress\",\"top\",\"bottom\",\"outerwear\",\"shoes\",\"bag\"]:\n",
        "        if sel.get(slot):\n",
        "            lines.append(f\"{slot.capitalize()}: {lookup(sel[slot])}\")\n",
        "\n",
        "    for a in sel.get(\"accessories\", []):\n",
        "        lines.append(f\"Accessory: {lookup(a)}\")\n",
        "\n",
        "    lines.append(\"\\nWhy this works:\\n\" + (data.get(\"explanation\") or \"\").strip())\n",
        "\n",
        "    if data.get(\"citations\"):\n",
        "        lines.append(\"Sources: \" + \", \".join(data[\"citations\"]))\n",
        "\n",
        "    if sel.get(\"_status\") == \"insufficient\":\n",
        "        lines.append(\"\\nNote: Could not complete a full outfit from the closet.\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ================== Example Run ==================\n",
        "if __name__ == \"__main__\":\n",
        "    # Create sample closet with new column structure\n",
        "    sample_csv = \"\"\"id,object,color,pattern,fabric\n",
        "T1,Black crewneck knit,black,solid,wool\n",
        "T2,Dark navy blouse,navy,solid,silk\n",
        "T3,White oxford shirt,white,solid,cotton\n",
        "T4,Striped Breton tee,navy/white,stripe,cotton\n",
        "T5,Charcoal merino turtleneck,charcoal,solid,wool\n",
        "T6,Ivory silk cami,ivory,solid,silk\n",
        "B1,Black linen pants,black,solid,linen\n",
        "B2,Charcoal wool trousers,charcoal,solid,wool\n",
        "B3,Dark indigo straight jeans,dark indigo,solid,denim\n",
        "B4,Black wide-leg trousers,black,solid,wool blend\n",
        "B5,Navy A-line midi skirt,navy,solid,wool\n",
        "D1,Deep green midi dress,deep green,solid,viscose\n",
        "D2,Black column dress,black,solid,crepe\n",
        "O1,Camel trench coat,camel,solid,cotton\n",
        "O2,Navy unstructured blazer,navy,solid,wool\n",
        "O3,Black wool overcoat,black,solid,wool\n",
        "O4,Cropped denim jacket,blue denim,solid,denim\n",
        "S1,Black leather loafers,black,solid,leather\n",
        "S2,Black ankle boots,black,solid,leather\n",
        "S3,White leather sneakers,white,solid,leather\n",
        "S4,Black strappy heels,black,solid,leather\n",
        "S5,Brown brogues,brown,solid,leather\n",
        "G1,Black structured tote,black,solid,leather\n",
        "G2,Slim black crossbody,black,solid,leather\n",
        "G3,Small metallic clutch,metallic,solid,leather\n",
        "A1,Small silver hoops,silver,solid,metal\n",
        "A2,Thin black belt,black,solid,leather\n",
        "A3,Gold pendant necklace,gold,solid,metal\n",
        "A4,Black wool scarf,black,solid,wool\"\"\"\n",
        "\n",
        "    with open(\"closet_min.csv\",\"w\") as f:\n",
        "        f.write(sample_csv)\n",
        "\n",
        "    # Test simple Q&A\n",
        "    print(\"=== Simple Q&A Test ===\")\n",
        "    user_query = \"How should I dress to a funeral if I want to use my black linen pants?\"\n",
        "    print(answer_question(user_query))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Test outfit generation\n",
        "    print(\"=== Outfit Generation Test ===\")\n",
        "    closet_df = load_closet(\"closet_min.csv\")\n",
        "    result = llm_outfit_from_closet(\n",
        "        user_query=user_query,\n",
        "        closet_df=closet_df,\n",
        "        doc_path=DOC_PATH,\n",
        "        k=6\n",
        "    )\n",
        "    print(render_outfit(result, closet_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6BetXUC-JdQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
